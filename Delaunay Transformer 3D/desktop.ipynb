{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REDO THIS WITHOUT KEEPING TRACK OF EDGES\n",
    "\n",
    "Idea: among removed triangles, pair up faces that both apear, left with faces that don't - the boundary, from which we construct new triangles\n",
    "\n",
    "have two lists, faces left to check, and faces to check against (these will be all 3 anticlockwise versions of each face)\n",
    "keep track of the batch you came from, and the index against which you are currently checking\n",
    "increase index by one each time until either: find a match, or: no longer checking against same batch\n",
    "at which point we remove FROM THE FIRST LIST\n",
    "repeat until all removed\n",
    "when find a match, mark it in second list\n",
    "removed all marked faces\n",
    "somehow find number remaining in each batch, and make sure to copy that many 'new points' into a long list\n",
    "construct new triangles from the above information\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "floattype = torch.float\n",
    "\n",
    "\n",
    "class environment:    \n",
    "    def reset(self, npoints, batchsize, nsamples=1, corner_points = None, initial_triangulation = None):\n",
    "        \"\"\"\n",
    "        corner_points, etc., shoudn't include a batch dimension\n",
    "        \"\"\"\n",
    "        if corner_points == None:\n",
    "            ncornerpoints = 4\n",
    "        else:\n",
    "            ncornerpoints = corner_points.size(0)\n",
    "        if npoints <= ncornerpoints:\n",
    "            print(\"Error: not enough points for valid problem instance\")\n",
    "            return\n",
    "        self.batchsize = (\n",
    "            batchsize * nsamples\n",
    "        )  # so that I don't have to rewrite all this code, we store these two dimensions together\n",
    "        self.nsamples = nsamples\n",
    "        self.npoints = npoints\n",
    "        self.points = (\n",
    "            torch.rand([batchsize, npoints - ncornerpoints, 3], dtype = floattype, device=device)\n",
    "            .unsqueeze(1)\n",
    "            .expand(-1, nsamples, -1, -1)\n",
    "            .reshape(self.batchsize, npoints - ncornerpoints, 3)\n",
    "        )\n",
    "        if corner_points == None:\n",
    "            self.corner_points = torch.tensor(\n",
    "                [[0, 0, 0], [3, 0, 0], [0, 3, 0], [0, 0, 3]], dtype = floattype, device=device\n",
    "            )\n",
    "        else:\n",
    "            self.corner_points = corner_points\n",
    "        self.points = torch.cat(\n",
    "            [\n",
    "                self.corner_points.unsqueeze(0).expand(self.batchsize, -1, -1),\n",
    "                self.points,\n",
    "            ],\n",
    "            dim=-2,\n",
    "        )  # [batchsize * nsamples, npoints, 3]\n",
    "        self.points_mask = torch.cat(\n",
    "            [\n",
    "                torch.ones([self.batchsize, ncornerpoints], dtype=torch.bool, device=device),\n",
    "                torch.zeros(\n",
    "                    [self.batchsize, npoints - ncornerpoints], dtype=torch.bool, device=device\n",
    "                ),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        self.points_sequence = torch.empty(\n",
    "            [self.batchsize, 0], dtype=torch.long, device=device\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        points are now triples\n",
    "        triangles are now quadruples\n",
    "        edges are now still just indices, but there are four of them per 'triangle', and they correspond to triples of points, not pairs\n",
    "        we use  0,2,1  0,3,2  0,1,3  1,2,3  as the order of the four 'edges'/faces\n",
    "        opposite face is always ordered such that the last two indices are swapped\n",
    "        faces are always read ANTICLOCKWISE\n",
    "        \n",
    "        first three points of tetrahedron MUST be read clockwise (from the outside) to get correct sign on incircle test\n",
    "        \n",
    "        new point will be inserted in zeroth position, so if corresponding face of REMOVED tetrahedron is [x,y,z] (being read anticlockwise from outside in) new tetrahedron is [p, x, y, z]\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        number of tetrahedra is not the same for each batch (in 3D), so store as a big list, and remember batch index that it comes from\n",
    "        \"\"\"\n",
    "        if corner_points == None:\n",
    "            initial_triangulation = torch.tensor([[0, 1, 2, 3]], dtype=torch.long, device=device)\n",
    "        \n",
    "        self.partial_delaunay_triangles = initial_triangulation.unsqueeze(0).expand(self.batchsize, -1, -1).reshape(-1, 4)\n",
    "        self.batch_index = torch.arange(self.batchsize, dtype = torch.long, device = device).unsqueeze(1).expand(-1, initial_triangulation.size(0)).reshape(-1)\n",
    "        \n",
    "        self.batch_triangles = self.partial_delaunay_triangles.size(0) #[0]\n",
    "        self.ntriangles = torch.full([self.batchsize], initial_triangulation.size(0), dtype = torch.long, device = device) #[self.batchsize]\n",
    "        \n",
    "        self.cost = torch.zeros([self.batchsize], dtype = floattype, device=device)\n",
    "\n",
    "        self.logprob = torch.zeros([self.batchsize], dtype = floattype, device=device, requires_grad=True)\n",
    "\n",
    "    def update(self, point_index):  # point_index is [batchsize]\n",
    "        \n",
    "        assert point_index.size(0) == self.batchsize\n",
    "        assert str(point_index.device) == device\n",
    "        assert self.points_mask.gather(1, point_index.unsqueeze(1)).sum() == 0\n",
    "        \n",
    "        triangles_coordinates = self.points[self.batch_index.unsqueeze(1), self.partial_delaunay_triangles] # [batch_triangles, 4, 3]\n",
    "        \n",
    "        newpoint = self.points[self.batch_index, point_index[self.batch_index]] # [batch_triangles, 3]\n",
    "\n",
    "        incircle_matrix = torch.cat(\n",
    "            [\n",
    "                newpoint.unsqueeze(1),\n",
    "                triangles_coordinates,\n",
    "            ],\n",
    "            dim=-2,\n",
    "        )  # [batch_triangles, 5, 3]\n",
    "        incircle_matrix = torch.cat(\n",
    "            [\n",
    "                (incircle_matrix * incircle_matrix).sum(-1, keepdim=True),\n",
    "                incircle_matrix,\n",
    "                torch.ones([self.batch_triangles, 5, 1], dtype = floattype, device=device),\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )  # [batch_triangles, 5, 5]\n",
    "        assert incircle_matrix.dtype == floattype\n",
    "        assert str(incircle_matrix.device) == device\n",
    "        \n",
    "        incircle_test = (\n",
    "            incircle_matrix.det() > 0\n",
    "        )  # [batch_triangles], is True if inside incircle\n",
    "        \n",
    "        conflicts = incircle_test.sum()\n",
    "        \n",
    "        conflicting_triangles = self.partial_delaunay_triangles[incircle_test] # [conflicts, 4]\n",
    "        \n",
    "        conflicting_edges_index0 = torch.empty_like(conflicting_triangles)\n",
    "        indices = torch.LongTensor([0, 0, 0, 1])\n",
    "        conflicting_edges_index0 = conflicting_triangles[:, indices] # [conflicts, 4]\n",
    "        \n",
    "        conflicting_edges_index1 = torch.empty_like(conflicting_triangles)\n",
    "        indices = torch.LongTensor([2, 3, 1, 2])\n",
    "        conflicting_edges_index1 = conflicting_triangles[:, indices] # [conflicts, 4]\n",
    "        \n",
    "        conflicting_edges_index2 = torch.empty_like(conflicting_triangles)\n",
    "        indices = torch.LongTensor([1, 2, 3, 3])\n",
    "        conflicting_edges_index2 = conflicting_triangles[:, indices] # [conflicts, 4]\n",
    "        \n",
    "        conflicting_edges = torch.cat([conflicting_edges_index0.view(-1).unsqueeze(-1), conflicting_edges_index1.view(-1).unsqueeze(-1), conflicting_edges_index2.view(-1).unsqueeze(-1)], dim = -1).reshape(-1, 3) # [conflicts * 4, 3]\n",
    "        \n",
    "        edge_batch_index = self.batch_index[incircle_test].unsqueeze(1).expand(-1, 4).reshape(-1) # [conflicts * 4]\n",
    "        \n",
    "        indices = torch.LongTensor([0, 2, 1])\n",
    "        comparison_edges = conflicting_edges[:, indices] # [conflicts * 4, 3]        \n",
    "        \n",
    "        unravel_nomatch_mask = torch.ones([conflicts * 4], dtype = torch.bool, device = device) # [conflicts * 4]\n",
    "        i = 1\n",
    "        while True:\n",
    "            \n",
    "            todo_mask = unravel_nomatch_mask[:-i].logical_and(edge_batch_index[:-i] == edge_batch_index[i:])\n",
    "            if i % 4 == 0:\n",
    "                if todo_mask.sum() == 0:\n",
    "                    break\n",
    "            \n",
    "            match_mask = todo_mask.clone()\n",
    "            match_mask[todo_mask] = (conflicting_edges[:-i][todo_mask] != comparison_edges[i:][todo_mask]).sum(-1).logical_not()\n",
    "            \n",
    "            unravel_nomatch_mask[:-i][match_mask] = False\n",
    "            unravel_nomatch_mask[i:][match_mask] = False\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        batch_newtriangles = unravel_nomatch_mask.sum()\n",
    "        \n",
    "        nomatch_edges = conflicting_edges[unravel_nomatch_mask] # [batch_newtriangles, 3], already in correct order to insert into 1,2,3 (since already anticlockwise from outside in)\n",
    "        assert list(nomatch_edges.size()) == [batch_newtriangles, 3]\n",
    "        nomatch_batch_index = edge_batch_index[unravel_nomatch_mask] # [batch_newtriangles]\n",
    "        \n",
    "        nomatch_newpoint = point_index[nomatch_batch_index] # [batch_newtriangles]\n",
    "        \n",
    "        newtriangles = torch.cat([nomatch_newpoint.unsqueeze(1), nomatch_edges], dim = -1) # [batch_newtriangles, 4]\n",
    "        \n",
    "        \n",
    "        nremoved_triangles = torch.zeros([self.batchsize], dtype = torch.long, device = device)\n",
    "        nnew_triangles = torch.zeros([self.batchsize], dtype = torch.long, device = device)\n",
    "        \n",
    "        indices = self.batch_index[incircle_test]\n",
    "        nremoved_triangles.put_(indices, torch.ones_like(indices, dtype = torch.long), accumulate = True) # [batchsize]\n",
    "        \n",
    "        indices = edge_batch_index[unravel_nomatch_mask]\n",
    "        nnew_triangles.put_(indices, torch.ones_like(indices, dtype = torch.long), accumulate = True) # [batchsize]\n",
    "        \n",
    "        assert (nnew_triangles <= 2 * nremoved_triangles + 2).logical_not().sum().logical_not()\n",
    "        \n",
    "        \"\"\"\n",
    "        NOTE:\n",
    "        I THINK it's possible for nnew_triangles to be less than nremoved_triangles (or my code is just buggy...)\n",
    "        \"\"\"\n",
    "        \n",
    "        assert nnew_triangles.sum() == batch_newtriangles\n",
    "        assert nremoved_triangles.sum() == incircle_test.sum()\n",
    "        \n",
    "        nadditional_triangles = nnew_triangles - nremoved_triangles # [batchsize]\n",
    "        ntriangles = self.ntriangles + nadditional_triangles # [batchsize]\n",
    "        \n",
    "        partial_delaunay_triangles = torch.empty([ntriangles.sum(), 4], dtype = torch.long, device = device)\n",
    "        batch_index = torch.empty([ntriangles.sum()], dtype = torch.long, device = device)\n",
    "        \n",
    "        cumulative_triangles = torch.cat([torch.zeros([1], dtype = torch.long, device = device), nnew_triangles.cumsum(0)[:-1]]) # [batchsize], cumulative sum starts at zero\n",
    "        \n",
    "        \"\"\"\n",
    "        since may actually have LESS triangles than previous round, we insert all that survive into the first slots (in that batch)\n",
    "        \"\"\"\n",
    "        good_triangle_indices = torch.arange(incircle_test.logical_not().sum(), dtype = torch.long, device = device)\n",
    "        good_triangle_indices += cumulative_triangles[self.batch_index[incircle_test.logical_not()]]\n",
    "        bad_triangle_indices_mask = torch.ones([ntriangles.sum(0)], dtype = torch.bool, device = device)\n",
    "        bad_triangle_indices_mask.scatter_(0, good_triangle_indices, False)\n",
    "        \n",
    "        assert good_triangle_indices.size(0) == incircle_test.logical_not().sum()\n",
    "        assert bad_triangle_indices_mask.sum() == batch_newtriangles\n",
    "        \n",
    "        partial_delaunay_triangles[good_triangle_indices] = self.partial_delaunay_triangles[~incircle_test]\n",
    "        batch_index[good_triangle_indices] = self.batch_index[~incircle_test]\n",
    "        \n",
    "        partial_delaunay_triangles[bad_triangle_indices_mask] = newtriangles\n",
    "        batch_index[bad_triangle_indices_mask] = nomatch_batch_index\n",
    "        \n",
    "        self.partial_delaunay_triangles = partial_delaunay_triangles\n",
    "        self.batch_index = batch_index\n",
    "        \n",
    "        self.ntriangles = ntriangles\n",
    "        self.batch_triangles = self.partial_delaunay_triangles.size(0)\n",
    "        \n",
    "        self.points_mask.scatter_(\n",
    "            1, point_index.unsqueeze(1).expand(-1, self.npoints), True\n",
    "        )\n",
    "        self.points_sequence = torch.cat(\n",
    "            [self.points_sequence, point_index.unsqueeze(1)], dim=1\n",
    "        )\n",
    "        \n",
    "        self.cost += nremoved_triangles\n",
    "        return\n",
    "    \n",
    "    def allindices(self): #generate all orders of point insertion\n",
    "        npoints = self.npoints - 4\n",
    "        allroutes = torch.empty([1, 0], dtype = torch.long, device = device)\n",
    "        for i in range(npoints):\n",
    "            nroutes = allroutes.size(0)\n",
    "            remaining_mask = torch.ones([nroutes], dtype = torch.bool, device = device).unsqueeze(1).expand(-1, npoints).clone().scatter_(-1, allroutes, False)\n",
    "            remaining_indices = remaining_mask.nonzero(as_tuple = True)[1]\n",
    "            allroutes = allroutes.unsqueeze(1).expand(-1, remaining_mask[0, :].sum(), -1)\n",
    "            allroutes = torch.cat([allroutes, remaining_indices.view(nroutes, -1).unsqueeze(2)], dim = -1).view(-1, allroutes.size(-1) + 1)\n",
    "        return allroutes #[npoints!, npoints]\n",
    "\n",
    "\n",
    "# turn integer x,y coords (in nxn grid) into position d (0 to n^2-1) along the Hilbert curve.\n",
    "def xy2d(n, x, y):\n",
    "    [x, y] = [math.floor(x), math.floor(y)]\n",
    "    [rx, ry, s, d] = [0, 0, 0, 0]\n",
    "    s = n / 2\n",
    "    s = math.floor(s)\n",
    "    while s > 0:\n",
    "        rx = (x & s) > 0  # bitwise and, and then boolean is it greater than 0?\n",
    "        ry = (y & s) > 0\n",
    "        d += s * s * ((3 * rx) ^ ry)\n",
    "        [x, y] = rot(n, x, y, rx, ry)\n",
    "        s = s / 2\n",
    "        s = math.floor(s)\n",
    "    return d\n",
    "\n",
    "\n",
    "def rot(n, x, y, rx, ry):\n",
    "    if ry == 0:\n",
    "        if rx == 1:\n",
    "            x = n - 1 - x\n",
    "            y = n - 1 - y\n",
    "        # Swap x and y\n",
    "        t = x\n",
    "        x = y\n",
    "        y = t\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def order(\n",
    "    n, points\n",
    "):  # turns tensor of points into integer distances along hilbert curve of itteration n\n",
    "    grid = n * points.to(\"cpu\")\n",
    "    x = torch.empty([grid.size(0)])\n",
    "    for i in range(points.size(0)):\n",
    "        x[i] = xy2d(n, grid[i, 0], grid[i, 1])\n",
    "    return x\n",
    "\n",
    "\"\"\"\n",
    "CURRENTLY ONLY 2D VERSION\n",
    "\"\"\"\n",
    "def hilbert_insertion(npoints=103, batchsize=200):\n",
    "    env.reset(npoints, batchsize)\n",
    "    points = env.points[:, 3:]  # [batchsize, npoints - 3]\n",
    "    insertion_order = torch.full([batchsize, npoints], float(\"inf\"), device=device)\n",
    "    for i in range(batchsize):\n",
    "        insertion_order[i, 3:] = order(\n",
    "            2 ** 6, points[i]\n",
    "        )  # number of possible positions is n ** 2\n",
    "    for i in range(npoints - 3):\n",
    "        next_index = insertion_order.min(-1)[1]\n",
    "        env.update(next_index)\n",
    "        insertion_order.scatter_(1, next_index.unsqueeze(1), float(\"inf\"))\n",
    "    print(env.cost.mean().item(), env.cost.var().sqrt().item())\n",
    "    return\n",
    "\n",
    "\n",
    "def random_insertion(npoints=104, batchsize=200):\n",
    "    env.reset(npoints, batchsize)\n",
    "    for i in range(npoints - 4):\n",
    "        env.update(torch.full([batchsize], i + 4, dtype=torch.long, device=device))\n",
    "    print(env.cost.mean().item(), env.cost.var().sqrt().item())\n",
    "    return\n",
    "\n",
    "    \"\"\"\n",
    "    UNDER CONSTRUCTION\n",
    "    \"\"\"\n",
    "def kdtree_insertion(npoints=103, batchsize=200):\n",
    "    env.reset(npoints, batchsize)\n",
    "    points = env.points[:, 3:]  # [batchsize, npoints - 3]\n",
    "    \n",
    "env = environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'environment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7f225ca288f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatchsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpoints\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'environment' is not defined"
     ]
    }
   ],
   "source": [
    "env = environment()\n",
    "npoints = 5\n",
    "batchsize = 1000\n",
    "        \n",
    "env.reset(npoints + 4, batchsize, math.factorial(npoints))\n",
    "allroutes = env.allindices() + 4\n",
    "allroutes = allroutes.unsqueeze(0).expand(batchsize, -1, -1).reshape(-1, npoints)\n",
    "for j in range(10):\n",
    "    for i in range(npoints):\n",
    "        env.update(allroutes[:, i])\n",
    "    print(env.cost.view(batchsize, -1).min(-1)[0].mean().item(), env.cost.mean().item())\n",
    "    env.reset(npoints + 4, batchsize, math.factorial(npoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.0 41.30714416503906\n",
      "30.0 41.79365158081055\n",
      "24.0 40.58571243286133\n",
      "29.0 41.32619094848633\n",
      "29.0 42.022220611572266\n",
      "28.0 42.44285583496094\n",
      "27.0 42.368255615234375\n",
      "30.0 40.32857131958008\n",
      "26.0 42.762699127197266\n",
      "26.0 42.60476303100586\n"
     ]
    }
   ],
   "source": [
    "env = environment()\n",
    "npoints = 9\n",
    "batchsize = 1\n",
    "        \n",
    "env.reset(npoints + 4, batchsize, math.factorial(npoints))\n",
    "allroutes = env.allindices() + 4\n",
    "allroutes = allroutes.unsqueeze(0).expand(batchsize, -1, -1).reshape(-1, npoints)\n",
    "for j in range(10):\n",
    "    for i in range(npoints):\n",
    "        env.update(allroutes[:, i])\n",
    "    print(env.cost.view(batchsize, -1).min(-1)[0].mean().item(), env.cost.mean().item())\n",
    "    env.reset(npoints + 4, batchsize, math.factorial(npoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:73] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1626531840 bytes. Buy new RAM!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c37872789458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallroutes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpoints\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-278534066542>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, point_index)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mmatch_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtodo_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[0mmatch_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtodo_mask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconflicting_edges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtodo_mask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mcomparison_edges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtodo_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0munravel_nomatch_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatch_mask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:73] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1626531840 bytes. Buy new RAM!"
     ]
    }
   ],
   "source": [
    "env = environment()\n",
    "npoints = 10\n",
    "batchsize = 1\n",
    "        \n",
    "env.reset(npoints + 4, batchsize, math.factorial(npoints))\n",
    "allroutes = env.allindices() + 4\n",
    "allroutes = allroutes.unsqueeze(0).expand(batchsize, -1, -1).reshape(-1, npoints)\n",
    "for j in range(10):\n",
    "    for i in range(npoints):\n",
    "        env.update(allroutes[:, i])\n",
    "    print(env.cost.view(batchsize, -1).min(-1)[0].mean().item(), env.cost.mean().item())\n",
    "    env.reset(npoints + 4, batchsize, math.factorial(npoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
