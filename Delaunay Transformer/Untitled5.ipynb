{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.5\n",
      "0.0 0.5\n",
      "0.0 0.5\n",
      "0.0 0.5\n",
      "0.0 0.5\n",
      "0.0 0.5\n",
      "0.0 0.5\n",
      "0.0 0.5\n",
      "0.0 0.5\n",
      "0.0 0.5\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "class environment():\n",
    "    def reset(self, npoints, batchsize, nsamples):\n",
    "        if npoints <= 3:\n",
    "            print(\"Error: not enough points for valid problem instance\")\n",
    "            return\n",
    "        self.batchsize = batchsize * nsamples #so that I don't have to rewrite all this code, we store these two dimensions together\n",
    "        self.nsamples = nsamples\n",
    "        self.npoints = npoints\n",
    "        self.points = torch.rand([batchsize, npoints - 3, 2], device = device).unsqueeze(1).expand(-1, nsamples, -1, -1).reshape(self.batchsize, npoints - 3, 2)\n",
    "        self.corner_points = torch.tensor([[0, 0], [2, 0], [0, 2]], dtype = torch.float, device = device)\n",
    "        self.points = torch.cat([self.corner_points.unsqueeze(0).expand(self.batchsize, -1, -1), self.points], dim = -2) #[batchsize * nsamples, npoints, 2]\n",
    "        self.points_mask = torch.cat([torch.ones([self.batchsize, 3], dtype = torch.bool, device = device), torch.zeros([self.batchsize, npoints - 3], dtype = torch.bool, device = device)], dim = 1)\n",
    "        self.points_sequence = torch.empty([self.batchsize, 0], dtype = torch.long, device = device)\n",
    "        \n",
    "        \"\"\"use a trick, for the purpose of an 'external' triangle that is always left untouched, which means we don't have to deal with boundary edges as being different. external triangle is [0, 1, 2] traversed clockwise...\"\"\"\n",
    "        self.partial_delaunay_triangles = torch.tensor([[0, 2, 1], [0, 1, 2]], dtype = torch.int64, device = device).unsqueeze(0).expand(self.batchsize, -1, -1).contiguous() #[batchsize, ntriangles, 3] contains index of points, always anticlockwise\n",
    "        self.partial_delaunay_edges = torch.tensor([5, 4, 3, 2, 1, 0], dtype = torch.int64, device = device).unsqueeze(0).expand(self.batchsize, -1).contiguous() #[batchsize, ntriangles * 3] contains location of corresponding edge (edges go in order 01, 12, 20). Edges will always flip since triangles are stored anticlockwise.\n",
    "        \n",
    "        self.ntriangles = 2 #can store as scalar, since will always be the same\n",
    "        self.cost = torch.zeros([self.batchsize], device = device)\n",
    "    \n",
    "    \n",
    "    def reset_copy(self, points, nsamples): #points is size [batchsize, npoints, 2]\n",
    "        self.batchsize = points.size(0) * nsamples\n",
    "        self.nsamples = nsamples\n",
    "        self.npoints = points.size(1) + 3\n",
    "        self.corner_points = torch.tensor([[0, 0], [2, 0], [0, 2]], dtype = torch.float, device = device)\n",
    "        self.points = torch.cat([self.corner_points.unsqueeze(0).expand(self.batchsize, -1, -1), points.unsqueeze(1).expand(-1, nsamples, -1, -1).reshape(-1, self.npoints - 3, 2)], dim = -2) #[batchsize * nsamples, npoints, 2]\n",
    "        self.points_mask = torch.cat([torch.ones([self.batchsize, 3], dtype = torch.bool, device = device), torch.zeros([self.batchsize, self.npoints - 3], dtype = torch.bool, device = device)], dim = 1)\n",
    "        self.points_sequence = torch.empty([self.batchsize, 0], dtype = torch.long, device = device)\n",
    "        \n",
    "        self.partial_delaunay_triangles = torch.tensor([[0, 2, 1], [0, 1, 2]], dtype = torch.int64, device = device).unsqueeze(0).expand(self.batchsize, -1, -1).contiguous() #[batchsize, ntriangles, 3] contains index of points, always anticlockwise\n",
    "        self.partial_delaunay_edges = torch.tensor([5, 4, 3, 2, 1, 0], dtype = torch.int64, device = device).unsqueeze(0).expand(self.batchsize, -1).contiguous()\n",
    "        \n",
    "        self.ntriangles = 2\n",
    "        self.cost = torch.zeros([self.batchsize], device = device)\n",
    "        \n",
    "    \n",
    "    def update(self, point_index): #point_index is [batchsize]\n",
    "        if point_index.size(0) != self.batchsize:\n",
    "            print(\"Error: point_index.size() doesn't match expected size, should be [batchsize]\")\n",
    "            return\n",
    "        if self.points_mask.gather(1, point_index.unsqueeze(1)).sum():\n",
    "            print(\"Error: some points already added\")\n",
    "            return\n",
    "        triangles_coordinates = self.points.gather(1, self.partial_delaunay_triangles.view(self.batchsize, self.ntriangles * 3).unsqueeze(2).expand(-1, -1, 2)).view(self.batchsize, self.ntriangles, 3, 2) #[batchsize, ntriangles, 3, 2]\n",
    "        newpoint = self.points.gather(1, point_index.unsqueeze(1).unsqueeze(2).expand(self.batchsize, 1, 2)).squeeze(1) #[batchsize, 2]\n",
    "        \n",
    "        incircle_matrix = torch.cat([triangles_coordinates, newpoint.unsqueeze(1).unsqueeze(2).expand(-1, self.ntriangles, 1, -1)], dim = -2) #[batchsize, ntriangles, 4, 2]\n",
    "        incircle_matrix = torch.cat([incircle_matrix, (incircle_matrix * incircle_matrix).sum(-1, keepdim = True), torch.ones([self.batchsize, self.ntriangles, 4, 1], device = device)], dim = -1) #[batchsize, ntriangles, 4, 4]\n",
    "        incircle_test = incircle_matrix.det() > 0 #[batchsize, ntriangles], is True if inside incircle\n",
    "        removed_edge_mask = incircle_test.unsqueeze(2).expand(-1, -1, 3).reshape(-1) #[batchsize * ntriangles * 3]\n",
    "        \n",
    "        edges = (self.partial_delaunay_edges + self.ntriangles * 3 * torch.arange(self.batchsize, device = device).unsqueeze(1)).view(-1) #[batchsize * ntriangles * 3]\n",
    "        neighbouring_edge = edges.masked_select(removed_edge_mask)\n",
    "        neighbouring_edge_mask = torch.zeros([self.batchsize * self.ntriangles * 3], device = device, dtype = torch.bool)\n",
    "        neighbouring_edge_mask[neighbouring_edge] = True\n",
    "        neighbouring_edge_mask = (neighbouring_edge_mask * removed_edge_mask.logical_not()) #[batchsize * ntriangles * 3]\n",
    "        \n",
    "        n_new_triangles = neighbouring_edge_mask.view(self.batchsize, -1).sum(-1) #[batchsize]\n",
    "        \n",
    "        new_point = point_index.unsqueeze(1).expand(-1, self.ntriangles * 3).masked_select(neighbouring_edge_mask.view(self.batchsize, -1))\n",
    "        \n",
    "        second_point_mask = neighbouring_edge_mask.view(self.batchsize, -1, 3) #[batchsize, ntriangles 3]\n",
    "        (first_point_indices0, first_point_indices1, first_point_indices2) = second_point_mask.nonzero(as_tuple = True)\n",
    "        first_point_indices2 = (first_point_indices2 != 2) * (first_point_indices2 + 1)\n",
    "        \n",
    "        first_point = self.partial_delaunay_triangles[first_point_indices0, first_point_indices1, first_point_indices2] #[?]\n",
    "        second_point = self.partial_delaunay_triangles.masked_select(second_point_mask) #[?]\n",
    "        \n",
    "        new_triangles_mask = torch.cat([incircle_test, torch.ones([self.batchsize, 2], dtype = torch.bool, device = device)], dim = 1) #[batchsize, ntriangles + 2]\n",
    "        \n",
    "        new_neighbouring_edges = 3 * new_triangles_mask.nonzero(as_tuple = True)[1] #[?], 3* since is the 01 edge of new triangles (see later)\n",
    "        self.partial_delaunay_edges.masked_scatter_(neighbouring_edge_mask.view(self.batchsize, -1), new_neighbouring_edges) #still [batchsize, ntriangles * 3] for now\n",
    "        \n",
    "        self.partial_delaunay_triangles = torch.cat([self.partial_delaunay_triangles, torch.empty([self.batchsize, 2, 3], dtype = torch.long, device = device)], dim = 1)\n",
    "        self.partial_delaunay_edges = torch.cat([self.partial_delaunay_edges, torch.empty([self.batchsize, 6], dtype = torch.long, device = device)], dim = 1)\n",
    "        new_triangles = torch.stack([first_point, second_point, new_point], dim = 1) #[?, 3], edge here is flipped compared to edge in neighbouring triangle (so first_point is the second point in neighbouring edge)\n",
    "        self.partial_delaunay_triangles.masked_scatter_(new_triangles_mask.unsqueeze(2).expand(-1, -1, 3), new_triangles) #[batchsize, ntriangles + 2, 3]\n",
    "        \n",
    "        new_edge01 = neighbouring_edge_mask.view(self.batchsize, -1).nonzero(as_tuple = True)[1] #[?]\n",
    "        \n",
    "        \"\"\"we are currently storing which triangles have to be inserted, via the edges along the perimeter of the delaunay cavity, we need to compute which edge is to the 'left'/'right' of each edge\"\"\"\n",
    "        \"\"\"don't have the memory to do a batchsize * n * n boolean search, don't have the speed to do a batchsize^2 search (as would be the case for sparse matrix or similar)\"\"\"\n",
    "        \"\"\"best alternative: rotate the edge around right point, repeat until hit edge in mask (will never go to an edge of a removed triangle before we hit edge in mask) should basically be order 1!!!!!\"\"\"\n",
    "        \n",
    "        neighbouring_edge_index = neighbouring_edge_mask.nonzero(as_tuple = True)[0] #[?]\n",
    "        next_neighbouring_edge_index = torch.empty_like(neighbouring_edge_index) #[?]\n",
    "        \n",
    "        rotating_flipped_neighbouring_edge_index = neighbouring_edge_mask.nonzero(as_tuple = True)[0] #[?], initialise\n",
    "        todo_mask = torch.ones_like(next_neighbouring_edge_index, dtype = torch.bool) #[?]\n",
    "        while todo_mask.sum():\n",
    "            rotating_neighbouring_edge_index = rotating_flipped_neighbouring_edge_index + 1 - 3 * (rotating_flipped_neighbouring_edge_index % 3 == 2) #[todo_mask.sum()], gets smaller until nothing left EFFICIENCY (this may be seriously stupid, as it requires making a bunch of copies when I could be doing stuff inplace)\n",
    "            \n",
    "            update_mask = neighbouring_edge_mask[rotating_neighbouring_edge_index] #[todo_mask.sum()]\n",
    "            update_mask_unravel = torch.zeros_like(todo_mask).masked_scatter(todo_mask, update_mask) #[?]\n",
    "            \n",
    "            next_neighbouring_edge_index.masked_scatter_(update_mask_unravel, rotating_neighbouring_edge_index.masked_select(update_mask)) #[?]\n",
    "            \n",
    "            todo_mask.masked_fill_(update_mask_unravel, False) #[?]\n",
    "            rotating_flipped_neighbouring_edge_index = edges[rotating_neighbouring_edge_index.masked_select(update_mask.logical_not())] #[todo_mask.sum()]\n",
    "        triangle_index = new_triangles_mask.view(-1).nonzero(as_tuple = True)[0] #[?], index goes up to batchsize * (ntriangles + 2), this is needed for when we invert the permutation by scattering (won't scatter same number of triangles per batch)\n",
    "        \n",
    "        next_triangle_index = torch.empty_like(edges).masked_scatter_(neighbouring_edge_mask, triangle_index)[next_neighbouring_edge_index] #[?], index goes up to batchsize * (ntriangles + 2)\n",
    "        next_edge = 3 * next_triangle_index + 1 #[?]\n",
    "        \n",
    "        invert_permutation = torch.empty_like(new_triangles_mask.view(-1), dtype=torch.long) #[batchsize * (ntriangles + 2)]\n",
    "        invert_permutation[next_triangle_index] = triangle_index #[batchsize * (ntriangles + 2)]\n",
    "        previous_triangle_index = invert_permutation.masked_select(new_triangles_mask.view(-1)) #[?]\n",
    "        previous_edge = 3 * previous_triangle_index + 2 #[?]\n",
    "        \n",
    "        \"\"\"in the above we rotated around 'first_point' in our new triangles\"\"\"\n",
    "        new_edge20 = next_edge % ((self.ntriangles + 2) * 3) #[?]\n",
    "        new_edge12 = previous_edge % ((self.ntriangles + 2) * 3) #[?]\n",
    "        \n",
    "        new_edges = torch.stack([new_edge01, new_edge12, new_edge20], dim = 1) #[?, 3]\n",
    "        self.partial_delaunay_edges.masked_scatter_(new_triangles_mask.unsqueeze(2).expand(-1, -1, 3).reshape(self.batchsize, -1), new_edges) #[batchsize, (ntriangles + 2) * 3]\n",
    "        \n",
    "        self.ntriangles += 2\n",
    "        \"\"\"currently only count the extra triangles you replace (not the on you have to remove because you're located there, and not the ones you make because you have to create two more\"\"\"\n",
    "        self.cost += (n_new_triangles - 3)\n",
    "        self.points_mask.scatter_(1, point_index.unsqueeze(1).expand(-1, self.npoints), True)\n",
    "        self.points_sequence = torch.cat([self.points_sequence, point_index.unsqueeze(1)], dim = 1)\n",
    "    \n",
    "    def allindices(self): #generate all orders of point insertion\n",
    "        npoints = self.npoints - 3\n",
    "        allroutes = torch.empty([1, 0], dtype = torch.long, device = device)\n",
    "        for i in range(npoints):\n",
    "            nroutes = allroutes.size(0)\n",
    "            remaining_mask = torch.ones([nroutes], dtype = torch.bool, device = device).unsqueeze(1).expand(-1, npoints).clone().scatter_(-1, allroutes, False)\n",
    "            remaining_indices = remaining_mask.nonzero(as_tuple = True)[1]\n",
    "            allroutes = allroutes.unsqueeze(1).expand(-1, remaining_mask[0, :].sum(), -1)\n",
    "            allroutes = torch.cat([allroutes, remaining_indices.view(nroutes, -1).unsqueeze(2)], dim = -1).view(-1, allroutes.size(-1) + 1)\n",
    "        return allroutes #[npoints!, npoints]\n",
    "\n",
    "\n",
    "env = environment()\n",
    "npoints = 2\n",
    "batchsize = 1000\n",
    "        \n",
    "env.reset(npoints + 3, batchsize, math.factorial(npoints))\n",
    "allroutes = env.allindices() + 3\n",
    "allroutes = allroutes.unsqueeze(0).expand(batchsize, -1, -1).reshape(-1, npoints)\n",
    "for j in range(10):\n",
    "    for i in range(npoints):\n",
    "        env.update(allroutes[:, i])\n",
    "    print(env.cost.view(batchsize, -1).min(-1)[0].mean().item(), env.cost.mean().item())\n",
    "    env.reset(npoints + 3, batchsize, math.factorial(npoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
