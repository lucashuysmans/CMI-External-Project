{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REDO THIS WITHOUT KEEPING TRACK OF EDGES\n",
    "\n",
    "Idea: among removed triangles, pair up faces that both apear, left with faces that don't - the boundary, from which we construct new triangles\n",
    "\n",
    "have two lists, faces left to check, and faces to check against (these will be all 3 anticlockwise versions of each face)\n",
    "keep track of the batch you came from, and the index against which you are currently checking\n",
    "increase index by one each time until either: find a match, or: no longer checking against same batch\n",
    "at which point we remove FROM THE FIRST LIST\n",
    "repeat until all removed\n",
    "when find a match, mark it in second list\n",
    "removed all marked faces\n",
    "somehow find number remaining in each batch, and make sure to copy that many 'new points' into a long list\n",
    "construct new triangles from the above information\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "floattype = torch.float\n",
    "\n",
    "\n",
    "class environment:    \n",
    "    def reset(self, npoints, batchsize, nsamples=1, corner_points = None, initial_triangulation = None):\n",
    "        \"\"\"\n",
    "        corner_points, etc., shoudn't include a batch dimension\n",
    "        \"\"\"\n",
    "        if corner_points == None:\n",
    "            ncornerpoints = 4\n",
    "        else:\n",
    "            ncornerpoints = corner_points.size(0)\n",
    "        if npoints <= ncornerpoints:\n",
    "            print(\"Error: not enough points for valid problem instance\")\n",
    "            return\n",
    "        self.batchsize = (\n",
    "            batchsize * nsamples\n",
    "        )  # so that I don't have to rewrite all this code, we store these two dimensions together\n",
    "        self.nsamples = nsamples\n",
    "        self.npoints = npoints\n",
    "        self.points = (\n",
    "            torch.rand([batchsize, npoints - ncornerpoints, 3], dtype = floattype, device=device)\n",
    "            .unsqueeze(1)\n",
    "            .expand(-1, nsamples, -1, -1)\n",
    "            .reshape(self.batchsize, npoints - ncornerpoints, 3)\n",
    "        )\n",
    "        if corner_points == None:\n",
    "            self.corner_points = torch.tensor(\n",
    "                [[0, 0, 0], [3, 0, 0], [0, 3, 0], [0, 0, 3]], dtype = floattype, device=device\n",
    "            )\n",
    "        else:\n",
    "            self.corner_points = corner_points\n",
    "        self.points = torch.cat(\n",
    "            [\n",
    "                self.corner_points.unsqueeze(0).expand(self.batchsize, -1, -1),\n",
    "                self.points,\n",
    "            ],\n",
    "            dim=-2,\n",
    "        )  # [batchsize * nsamples, npoints, 3]\n",
    "        self.points_mask = torch.cat(\n",
    "            [\n",
    "                torch.ones([self.batchsize, ncornerpoints], dtype=torch.bool, device=device),\n",
    "                torch.zeros(\n",
    "                    [self.batchsize, npoints - ncornerpoints], dtype=torch.bool, device=device\n",
    "                ),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        self.points_sequence = torch.empty(\n",
    "            [self.batchsize, 0], dtype=torch.long, device=device\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        points are now triples\n",
    "        triangles are now quadruples\n",
    "        edges are now still just indices, but there are four of them per 'triangle', and they correspond to triples of points, not pairs\n",
    "        we use  0,2,1  0,3,2  0,1,3  1,2,3  as the order of the four 'edges'/faces\n",
    "        opposite face is always ordered such that the last two indices are swapped\n",
    "        faces are always read ANTICLOCKWISE\n",
    "        \n",
    "        first three points of tetrahedron MUST be read clockwise (from the outside) to get correct sign on incircle test\n",
    "        \n",
    "        new point will be inserted in zeroth position, so if corresponding face of REMOVED tetrahedron is [x,y,z] (being read anticlockwise from outside in) new tetrahedron is [p, x, y, z]\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        number of tetrahedra is not the same for each batch (in 3D), so store as a big list, and remember batch index that it comes from\n",
    "        \"\"\"\n",
    "        if corner_points == None:\n",
    "            initial_triangulation = torch.tensor([[0, 1, 2, 3]], dtype=torch.long, device=device)\n",
    "        \n",
    "        self.partial_delaunay_triangles = initial_triangulation.unsqueeze(0).expand(self.batchsize, -1, -1).reshape(-1, 4)\n",
    "        self.batch_index = torch.arange(self.batchsize, dtype = torch.long, device = device).unsqueeze(1).expand(-1, initial_triangulation.size(0)).reshape(-1)\n",
    "        \n",
    "        self.batch_triangles = self.partial_delaunay_triangles.size(0) #[0]\n",
    "        self.ntriangles = torch.full([self.batchsize], initial_triangulation.size(0), dtype = torch.long, device = device) #[self.batchsize]\n",
    "        \n",
    "        self.cost = torch.zeros([self.batchsize], dtype = floattype, device=device)\n",
    "\n",
    "        self.logprob = torch.zeros([self.batchsize], dtype = floattype, device=device, requires_grad=True)\n",
    "\n",
    "    def update(self, point_index):  # point_index is [batchsize]\n",
    "        \n",
    "        assert point_index.size(0) == self.batchsize\n",
    "        assert str(point_index.device) == device\n",
    "        assert self.points_mask.gather(1, point_index.unsqueeze(1)).sum() == 0\n",
    "        \n",
    "        triangles_coordinates = self.points[self.batch_index.unsqueeze(1), self.partial_delaunay_triangles] # [batch_triangles, 4, 3]\n",
    "        assert list(triangles_coordinates.size()) == [self.batch_triangles, 4, 3]\n",
    "        \n",
    "        newpoint = self.points[self.batch_index, point_index[self.batch_index]] # [batch_triangles, 3]\n",
    "        assert list(newpoint.size()) == [self.batch_triangles, 3]\n",
    "\n",
    "        incircle_matrix = torch.cat(\n",
    "            [\n",
    "                newpoint.unsqueeze(1),\n",
    "                triangles_coordinates,\n",
    "            ],\n",
    "            dim=-2,\n",
    "        )  # [batch_triangles, 5, 3]\n",
    "        incircle_matrix = torch.cat(\n",
    "            [\n",
    "                (incircle_matrix * incircle_matrix).sum(-1, keepdim=True),\n",
    "                incircle_matrix,\n",
    "                torch.ones([self.batch_triangles, 5, 1], dtype = floattype, device=device),\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )  # [batch_triangles, 5, 5]\n",
    "        assert incircle_matrix.dtype == floattype\n",
    "        assert str(incircle_matrix.device) == device\n",
    "        \n",
    "        incircle_test = (\n",
    "            incircle_matrix.det() > 0\n",
    "        )  # [batch_triangles], is True if inside incircle\n",
    "        assert list(incircle_test.size()) == [self.batch_triangles]\n",
    "        \n",
    "        conflicts = incircle_test.sum()\n",
    "        \n",
    "        conflicting_triangles = self.partial_delaunay_triangles[incircle_test] # [conflicts, 4]\n",
    "        assert list(conflicting_triangles.size()) == [conflicts, 4]\n",
    "        \n",
    "        conflicting_edges_index0 = torch.empty_like(conflicting_triangles)\n",
    "        indices = torch.LongTensor([0, 0, 0, 1])\n",
    "        conflicting_edges_index0 = conflicting_triangles[:, indices] # [conflicts, 4]\n",
    "        \n",
    "        conflicting_edges_index1 = torch.empty_like(conflicting_triangles)\n",
    "        indices = torch.LongTensor([2, 3, 1, 2])\n",
    "        conflicting_edges_index1 = conflicting_triangles[:, indices] # [conflicts, 4]\n",
    "        \n",
    "        conflicting_edges_index2 = torch.empty_like(conflicting_triangles)\n",
    "        indices = torch.LongTensor([1, 2, 3, 3])\n",
    "        conflicting_edges_index2 = conflicting_triangles[:, indices] # [conflicts, 4]\n",
    "        \n",
    "        conflicting_edges = torch.cat([conflicting_edges_index0.view(-1).unsqueeze(-1), conflicting_edges_index1.view(-1).unsqueeze(-1), conflicting_edges_index2.view(-1).unsqueeze(-1)], dim = -1).reshape(-1, 3) # [conflicts * 4, 3]\n",
    "        assert list(conflicting_edges.size()) == [conflicts * 4, 3]\n",
    "        \n",
    "        conflicting_edges_copy = conflicting_edges.clone() # [conflicts * 4, 3], for later use to construct the new triangles\n",
    "        \n",
    "        edge_batch_index = self.batch_index[incircle_test].unsqueeze(1).expand(-1, 4).reshape(-1) # [conflicts * 4]\n",
    "        assert list(edge_batch_index.size()) == [conflicts * 4]\n",
    "        assert str(edge_batch_index.device) == device\n",
    "        \n",
    "        indices = torch.LongTensor([0, 2, 1])\n",
    "        comparison_edges = conflicting_edges[:, indices] # [conflicts * 4, 3]\n",
    "        assert list(comparison_edges.size()) == [conflicts * 4, 3]\n",
    "        \n",
    "        unravel_nomatch_mask = torch.ones([conflicts * 4], dtype = torch.bool, device = device) # [conflicts * 4]\n",
    "        \n",
    "        edge_batch_index_extended = torch.cat([edge_batch_index, torch.tensor([-1], dtype = torch.long, device = device)])\n",
    "        \n",
    "        starting_index = torch.arange(conflicts * 4, dtype = torch.long, device = device) # [conflicts * 4]\n",
    "        current_comparison_index = starting_index.clone() # [conflicts * 4]\n",
    "        batch_index_todo = edge_batch_index.clone()\n",
    "        todo_mask = torch.ones([conflicts * 4], dtype = torch.bool, device = device) # [conflicts * 4]\n",
    "        while todo_mask.sum():\n",
    "            \n",
    "            if todo_mask.sum() < todo_mask.size(0) // 2:\n",
    "                conflicting_edges = conflicting_edges[todo_mask]\n",
    "                current_comparison_index = current_comparison_index[todo_mask]\n",
    "                starting_index = starting_index[todo_mask]\n",
    "                batch_index_todo = batch_index_todo[todo_mask]\n",
    "                todo_mask = torch.ones([todo_mask.sum()], dtype = torch.bool, device = device)\n",
    "            \n",
    "            assert conflicting_edges.size(0) == todo_mask.size(0)\n",
    "            assert current_comparison_index.size() == todo_mask.size()\n",
    "            assert batch_index_todo.size() == todo_mask.size()\n",
    "            \n",
    "            nomatch_mask = (conflicting_edges != comparison_edges[current_comparison_index]).sum(-1).bool()#.logical_or(batch_index_todo != edge_batch_index_extended[current_comparison_index])\n",
    "            \n",
    "            match_mask = nomatch_mask.logical_not().logical_and(todo_mask)\n",
    "            match_index0 = starting_index[match_mask]\n",
    "            match_index1 = current_comparison_index[match_mask]\n",
    "            assert unravel_nomatch_mask[match_index0].logical_not().sum().logical_not()\n",
    "            assert unravel_nomatch_mask[match_index1].logical_not().sum().logical_not()\n",
    "            unravel_nomatch_mask[match_index0] = False\n",
    "            unravel_nomatch_mask[match_index1] = False\n",
    "            \n",
    "            todo_mask = todo_mask.logical_and(nomatch_mask).logical_and(batch_index_todo == edge_batch_index_extended[current_comparison_index + 1])\n",
    "            \n",
    "            current_comparison_index = (current_comparison_index + 1) * todo_mask\n",
    "        \n",
    "        batch_newtriangles = unravel_nomatch_mask.sum()\n",
    "        \n",
    "        nomatch_edges = conflicting_edges_copy[unravel_nomatch_mask] # [batch_newtriangles, 3], already in correct order to insert into 1,2,3 (since already anticlockwise from outside in)\n",
    "        assert list(nomatch_edges.size()) == [batch_newtriangles, 3]\n",
    "        nomatch_batch_index = edge_batch_index[unravel_nomatch_mask] # [batch_newtriangles]\n",
    "        \n",
    "        nomatch_newpoint = point_index[nomatch_batch_index] # [batch_newtriangles]\n",
    "        \n",
    "        newtriangles = torch.cat([nomatch_newpoint.unsqueeze(1), nomatch_edges], dim = -1) # [batch_newtriangles, 4]\n",
    "        \n",
    "        \n",
    "        nremoved_triangles = torch.zeros([self.batchsize], dtype = torch.long, device = device)\n",
    "        nnew_triangles = torch.zeros([self.batchsize], dtype = torch.long, device = device)\n",
    "        \n",
    "        indices = self.batch_index[incircle_test]\n",
    "        nremoved_triangles.put_(indices, torch.ones_like(indices, dtype = torch.long), accumulate = True) # [batchsize]\n",
    "        \n",
    "        indices = edge_batch_index[unravel_nomatch_mask]\n",
    "        nnew_triangles.put_(indices, torch.ones_like(indices, dtype = torch.long), accumulate = True) # [batchsize]\n",
    "        \n",
    "        if (nnew_triangles > 2 * nremoved_triangles + 2).sum():\n",
    "            print(nnew_triangles, nremoved_triangles)\n",
    "        \n",
    "        assert (nnew_triangles <= 2 * nremoved_triangles + 2).logical_not().sum().logical_not()\n",
    "        \"\"\"\n",
    "        should always be <=\n",
    "        can sometimes not be equal\n",
    "        if equal, this would mean the total removed triangles is determined by the UNIQUE final delaunay triangulation ... and the same would probably be true in any number of dimensions greater than 2 ...\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        NOTE:\n",
    "        I THINK it's possible for nnew_triangles to be less than nremoved_triangles (or my code is just buggy...)\n",
    "        \"\"\"\n",
    "        \n",
    "        assert nnew_triangles.sum() == batch_newtriangles\n",
    "        assert nremoved_triangles.sum() == incircle_test.sum()\n",
    "        \n",
    "        nadditional_triangles = nnew_triangles - nremoved_triangles # [batchsize]\n",
    "        ntriangles = self.ntriangles + nadditional_triangles # [batchsize]\n",
    "        \n",
    "        partial_delaunay_triangles = torch.empty([ntriangles.sum(), 4], dtype = torch.long, device = device)\n",
    "        batch_index = torch.empty([ntriangles.sum()], dtype = torch.long, device = device)\n",
    "        \n",
    "        cumulative_triangles = torch.cat([torch.zeros([1], dtype = torch.long, device = device), nnew_triangles.cumsum(0)[:-1]]) # [batchsize], cummulative sum starts at zero\n",
    "        \n",
    "        \"\"\"\n",
    "        since may actually have LESS triangles than previous round, we insert all that survive into the first slots (in that batch)\n",
    "        \"\"\"\n",
    "        good_triangle_indices = torch.arange(incircle_test.logical_not().sum(), dtype = torch.long, device = device)\n",
    "        good_triangle_indices += cumulative_triangles[self.batch_index[incircle_test.logical_not()]]\n",
    "        bad_triangle_indices_mask = torch.ones([ntriangles.sum(0)], dtype = torch.bool, device = device)\n",
    "        bad_triangle_indices_mask.scatter_(0, good_triangle_indices, False)\n",
    "        \n",
    "        assert good_triangle_indices.size(0) == incircle_test.logical_not().sum()\n",
    "        assert bad_triangle_indices_mask.sum() == batch_newtriangles\n",
    "        \n",
    "        partial_delaunay_triangles[good_triangle_indices] = self.partial_delaunay_triangles[~incircle_test]\n",
    "        batch_index[good_triangle_indices] = self.batch_index[~incircle_test]\n",
    "        \n",
    "        partial_delaunay_triangles[bad_triangle_indices_mask] = newtriangles\n",
    "        batch_index[bad_triangle_indices_mask] = nomatch_batch_index\n",
    "        \n",
    "        self.partial_delaunay_triangles = partial_delaunay_triangles\n",
    "        self.batch_index = batch_index\n",
    "        \n",
    "        self.ntriangles = ntriangles\n",
    "        assert list(self.partial_delaunay_triangles.size()) == [self.ntriangles.sum(), 4]\n",
    "        self.batch_triangles = self.partial_delaunay_triangles.size(0)\n",
    "        \n",
    "        self.points_mask.scatter_(\n",
    "            1, point_index.unsqueeze(1).expand(-1, self.npoints), True\n",
    "        )\n",
    "        self.points_sequence = torch.cat(\n",
    "            [self.points_sequence, point_index.unsqueeze(1)], dim=1\n",
    "        )\n",
    "        \n",
    "        self.cost += nnew_triangles\n",
    "\n",
    "\n",
    "# turn integer x,y coords (in nxn grid) into position d (0 to n^2-1) along the Hilbert curve.\n",
    "def xy2d(n, x, y):\n",
    "    [x, y] = [math.floor(x), math.floor(y)]\n",
    "    [rx, ry, s, d] = [0, 0, 0, 0]\n",
    "    s = n / 2\n",
    "    s = math.floor(s)\n",
    "    while s > 0:\n",
    "        rx = (x & s) > 0  # bitwise and, and then boolean is it greater than 0?\n",
    "        ry = (y & s) > 0\n",
    "        d += s * s * ((3 * rx) ^ ry)\n",
    "        [x, y] = rot(n, x, y, rx, ry)\n",
    "        s = s / 2\n",
    "        s = math.floor(s)\n",
    "    return d\n",
    "\n",
    "\n",
    "def rot(n, x, y, rx, ry):\n",
    "    if ry == 0:\n",
    "        if rx == 1:\n",
    "            x = n - 1 - x\n",
    "            y = n - 1 - y\n",
    "        # Swap x and y\n",
    "        t = x\n",
    "        x = y\n",
    "        y = t\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def order(\n",
    "    n, points\n",
    "):  # turns tensor of points into integer distances along hilbert curve of itteration n\n",
    "    grid = n * points.to(\"cpu\")\n",
    "    x = torch.empty([grid.size(0)])\n",
    "    for i in range(points.size(0)):\n",
    "        x[i] = xy2d(n, grid[i, 0], grid[i, 1])\n",
    "    return x\n",
    "\n",
    "\n",
    "def hilbert_insertion(npoints=103, batchsize=200):\n",
    "    env.reset(npoints, batchsize)\n",
    "    points = env.points[:, 3:]  # [batchsize, npoints - 3]\n",
    "    insertion_order = torch.full([batchsize, npoints], float(\"inf\"), device=device)\n",
    "    for i in range(batchsize):\n",
    "        insertion_order[i, 3:] = order(\n",
    "            2 ** 6, points[i]\n",
    "        )  # number of possible positions is n ** 2\n",
    "    for i in range(npoints - 3):\n",
    "        next_index = insertion_order.min(-1)[1]\n",
    "        env.update(next_index)\n",
    "        insertion_order.scatter_(1, next_index.unsqueeze(1), float(\"inf\"))\n",
    "    print(env.cost.mean().item(), env.cost.var().sqrt().item())\n",
    "\n",
    "\n",
    "def random_insertion(npoints=104, batchsize=200):\n",
    "    env.reset(npoints, batchsize)\n",
    "    for i in range(npoints - 4):\n",
    "        env.update(torch.full([batchsize], i + 4, dtype=torch.long, device=device))\n",
    "    print(env.cost.mean().item(), env.cost.var().sqrt().item())\n",
    "\n",
    "    \"\"\"\n",
    "    UNDER CONSTRUCTION\n",
    "    \"\"\"\n",
    "def kdtree_insertion(npoints=103, batchsize=200):\n",
    "    env.reset(npoints, batchsize)\n",
    "    points = env.points[:, 3:]  # [batchsize, npoints - 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29659.0 nan\n"
     ]
    }
   ],
   "source": [
    "random_insertion(10003, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40137.0 nan\n"
     ]
    }
   ],
   "source": [
    "hilbert_insertion(10003, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59681.0 nan\n"
     ]
    }
   ],
   "source": [
    "random_insertion(20003, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89729.0 nan\n"
     ]
    }
   ],
   "source": [
    "env = environment()\n",
    "random_insertion(30003,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87037.0 nan\n"
     ]
    }
   ],
   "source": [
    "hilbert_insertion(20003,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299925.0 nan\n"
     ]
    }
   ],
   "source": [
    "random_insertion(100003,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375598.0 nan\n"
     ]
    }
   ],
   "source": [
    "hilbert_insertion(100003,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_insertion(360003,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hilbert_insertion(360003,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand([5])\n",
    "a.dtype == torch.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = environment()\n",
    "random_insertion(1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
