{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "specified-mobile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 17 21:13:15 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.118.02   Driver Version: 440.118.02   CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   35C    P0   158W / 250W |  16227MiB / 16280MiB |     76%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   51C    P0   155W / 250W |  15783MiB / 16280MiB |     93%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     17702      C   ...ments/pytorch-1.8.0-cuda10.2/bin/python 16217MiB |\n",
      "|    1      6650      C   ...ments/pytorch-1.8.0-cuda10.2/bin/python 15773MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "statewide-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "device = \"cpu\"\n",
    "floattype = torch.float\n",
    "\n",
    "\n",
    "class environment:    \n",
    "    def reset(self, npoints, batchsize, nsamples=1):\n",
    "        self.batchsize = (\n",
    "            batchsize * nsamples\n",
    "        )  # so that I don't have to rewrite all this code, we store these two dimensions together\n",
    "        self.nsamples = nsamples\n",
    "        self.npoints = npoints\n",
    "        self.points = (\n",
    "            torch.rand([batchsize, npoints, 2], dtype = floattype, device=device)\n",
    "            .unsqueeze(1)\n",
    "            .expand(-1, nsamples, -1, -1)\n",
    "            .reshape(self.batchsize, npoints, 2)\n",
    "        )\n",
    "        \n",
    "        self.distance_matrix = (self.points.unsqueeze(1) - self.points.unsqueeze(2)).square().sum(-1).sqrt() # [batchsize * nsamples, npoints, npoints]\n",
    "        \n",
    "        self.previous_point = None\n",
    "        \n",
    "        self.points_mask = torch.zeros(\n",
    "                    [self.batchsize, npoints], dtype=torch.bool, device=device\n",
    "                )\n",
    "        self.points_sequence = torch.empty(\n",
    "            [self.batchsize, 0], dtype=torch.long, device=device\n",
    "        )\n",
    "        \n",
    "        self.cost = torch.zeros([self.batchsize], dtype = floattype, device=device)\n",
    "\n",
    "        self.logprob = torch.zeros([self.batchsize], dtype = floattype, device=device, requires_grad=True)\n",
    "\n",
    "    def update(self, point_index):  # point_index is [batchsize]\n",
    "        \n",
    "        assert list(point_index.size()) == [self.batchsize]\n",
    "        assert str(point_index.device) == device\n",
    "        assert self.points_mask.gather(1, point_index.unsqueeze(1)).sum() == 0\n",
    "        \n",
    "        if self.previous_point != None:\n",
    "            self.cost += self.distance_matrix.gather(2, self.previous_point.unsqueeze(1).unsqueeze(2).expand(-1, self.npoints, 1)).squeeze(2).gather(1, point_index.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        self.previous_point = point_index\n",
    "        self.points_mask.scatter_(1, point_index.unsqueeze(1), True)\n",
    "        self.points_sequence = torch.cat([self.points_sequence, point_index.unsqueeze(1)], dim = 1)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def laststep(self):\n",
    "        \n",
    "        assert self.points_sequence.size(1) == self.npoints\n",
    "        \n",
    "        self.cost += self.distance_matrix.gather(2, self.points_sequence[:, 0].unsqueeze(1).unsqueeze(2).expand(-1, self.npoints, 1)).squeeze(2).gather(1, self.points_sequence[:, -1].unsqueeze(1)).squeeze(1)\n",
    "    \n",
    "\n",
    "\n",
    "def farthest_insertion(npoints, batchsize):\n",
    "    \n",
    "    points = torch.rand([batchsize, npoints, 2], device = device)\n",
    "    points_mask = torch.zeros([batchsize, npoints], dtype=torch.bool, device=device)\n",
    "    distance_matrix = (points.unsqueeze(1) - points.unsqueeze(2)).square().sum(-1).sqrt() # [batchsize * nsamples, npoints, npoints]\n",
    "    \n",
    "    max_distances, second_point = distance_matrix.max(2) #[batchsize, npoints], [batchsize, npoints]\n",
    "    running_cost, first_point = max_distances.max(1) #[batchsize], [batchsize]\n",
    "    \n",
    "    running_cost *= 2\n",
    "    \n",
    "    points_sequence = torch.stack([first_point, second_point.gather(1, first_point.unsqueeze(1)).squeeze(1)], dim = 1) #[batchsize, sequence]\n",
    "    points_mask = points_mask.scatter(1, points_sequence, True)\n",
    "    \n",
    "    for i in range(2, npoints):\n",
    "        \n",
    "        assert points_sequence.size(1) == i\n",
    "        assert points_mask.sum() == batchsize * i\n",
    "        npoints_inserted = i\n",
    "        \n",
    "        distance_from_tour = (\n",
    "            distance_matrix\n",
    "            .masked_select(points_mask\n",
    "                           .unsqueeze(1)\n",
    "                           .expand(-1, npoints, -1)\n",
    "                          )\n",
    "            .view(batchsize, npoints, -1)\n",
    "            .min(2)[0]\n",
    "        ) #[batchsize, npoints]\n",
    "        \n",
    "        next_point = distance_from_tour.max(1)[1] #[batchsize], is index of point\n",
    "        \n",
    "        points_mask.scatter_(1, next_point.unsqueeze(1), True)\n",
    "        \n",
    "        insertion_cost = (\n",
    "            \n",
    "            distance_matrix\n",
    "            .gather(\n",
    "                1,\n",
    "                points_sequence\n",
    "                .roll(1, 1)\n",
    "                .unsqueeze(2)\n",
    "                .expand(-1, -1, npoints)\n",
    "            )\n",
    "            .gather(\n",
    "                2,\n",
    "                next_point\n",
    "                .unsqueeze(1)\n",
    "                .unsqueeze(2)\n",
    "                .expand(-1, i ,1)\n",
    "            )\n",
    "            .squeeze(2) #[batchsize, sequence]\n",
    "            \n",
    "            + distance_matrix\n",
    "            .gather(\n",
    "                1,\n",
    "                next_point\n",
    "                .unsqueeze(1)\n",
    "                .unsqueeze(2)\n",
    "                .expand(-1, i ,npoints)\n",
    "            )\n",
    "            .gather(\n",
    "                2,\n",
    "                points_sequence\n",
    "                .unsqueeze(2)\n",
    "            )\n",
    "            .squeeze(2) #[batchsize, sequence] \n",
    "            \n",
    "            - distance_matrix\n",
    "            .gather(\n",
    "                1,\n",
    "                points_sequence\n",
    "                .roll(1, 1)\n",
    "                .unsqueeze(2)\n",
    "                .expand(-1, -1, npoints)\n",
    "            )\n",
    "            .gather(\n",
    "                2, \n",
    "                points_sequence\n",
    "                .unsqueeze(2)\n",
    "            )\n",
    "            .squeeze(2) #[batchsize, sequence]\n",
    "            \n",
    "        ) #[batchsize, sequence]\n",
    "        \n",
    "        min_insertion_cost, insertion_location = insertion_cost.min(1) #[batchsize], [batchsize]\n",
    "        \n",
    "        running_cost += min_insertion_cost\n",
    "        \n",
    "        insertion_indices = ((\n",
    "            torch.arange(npoints_inserted, device = device)\n",
    "            .unsqueeze(0)\n",
    "            .expand(batchsize, -1)\n",
    "            + insertion_location.unsqueeze(1))\n",
    "            % npoints_inserted\n",
    "        ) #[batchsize, sequence]\n",
    "        \n",
    "        new_points_sequence = torch.cat([points_sequence.gather(1, insertion_indices), next_point.unsqueeze(1)], dim = 1)\n",
    "        \n",
    "        points_sequence = new_points_sequence #[batchsize, sequence + 1]\n",
    "    \n",
    "    pair_distances = distance_matrix.gather(1, points_sequence.unsqueeze(2).expand(-1, -1, npoints)).gather(2, points_sequence.roll(1, 1).unsqueeze(2)).squeeze(2) #[batchsize, sequence]\n",
    "    total_cost = pair_distances.sum(1)\n",
    "    \n",
    "    return total_cost.mean()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "coated-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.3708)\n",
      "tensor(25.7802)\n",
      "tensor(26.5136)\n",
      "tensor(25.6348)\n",
      "tensor(25.8166)\n",
      "tensor(25.9177)\n",
      "tensor(26.0191)\n",
      "tensor(25.9999)\n",
      "tensor(25.5729)\n",
      "tensor(25.1513)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(farthest_insertion(1000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(farthest_insertion(1000, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mental-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 18 00:04:34 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.118.02   Driver Version: 440.118.02   CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   58C    P0   169W / 250W |  16229MiB / 16280MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    32W / 250W |    813MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     26844      C   ...ments/pytorch-1.8.0-cuda10.2/bin/python 16219MiB |\n",
      "|    1     28867      C   ...ments/pytorch-1.8.0-cuda10.2/bin/python   803MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "             total       used       free     shared    buffers     cached\n",
      "Mem:        385627       6521     379106         46          2       2351\n",
      "-/+ buffers/cache:       4167     381460\n",
      "Swap:       196614        137     196477\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi\n",
    "free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-obligation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
